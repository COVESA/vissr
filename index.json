[
{
	"uri": "https://covesa.github.io/vissr/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://covesa.github.io/vissr/",
	"title": "COVESA Vehicle Information Service Specification version 3 Reference Implementation Tutorial",
	"tags": [],
	"description": "",
	"content": "COVESA Vehicle Information Service Specification ver 3 Reference Implementation Tutorial The COVESA VISSv3 specification is under development at the COVESA VISS Github. A VISSv3.0 reference implementation in the form of a server that exposes an interface according to the specification is developed on the master branch, while a VISSv2.0 reference implementation is available on the v2.0 branch.\nThis documentation covers the VISSv3.0 specification. The new features are listed below. It is with a few exceptions backwards compatible with VISSv2.0. The exceptions are listed below.\nVISSv3.0 new features Multiple tree support. The server can be configured to manage multiple trees that a client can access. Server capabilities. A Server tree can be accessed by clients. File transfer. Upload/download of files is available on Websocket. Data compression. Request local path compression and Request relative timestamp compression is available on Websocket. Protobuf encoding is available on Websocket. gRPC support. This wa already available on an experimental level in VISSR @v2.0. JSON scheme used to validate client requests. Error responses due to JSON scheme errors contain a description generated by the JSON scheme validator. Non-backwards compatible changes from VISSv2.0 The filter keyname \u0026ldquo;type\u0026rdquo; is changed to \u0026ldquo;variant\u0026rdquo;. The filter variants \u0026ldquo;static-metadata\u0026rdquo; and \u0026ldquo;dynamic-metadata\u0026rdquo; are replaced by the variant \u0026ldquo;metadata\u0026rdquo;. The \u0026ldquo;subscriptionId\u0026rdquo; parameter in unsubscribe response messages is deleted. The filter:metadata:parameter value is changed to represent the number of descendant generations that are returned. The error object keyword \u0026ldquo;message\u0026rdquo; is changed to \u0026ldquo;description\u0026rdquo;. The error:decription values are not normative any more. Also found on this repo are implementations of other components that are needed to realize a communication tech stack that reaches from clients through the server and to the underlying vehicle system interface.\nThese software components (SwCs) can be categorized as follows:\nserver clients data storage feeders tools The tutorial describes each SwC category in a separate chapter. It also contains a few Proof of concept (POC) examples, and information about installing, building and running Golang based SwCs, a Docker containerization, and about some peripheral components.\n"
},
{
	"uri": "https://covesa.github.io/vissr/pocs/poc2/",
	"title": "Next POC...",
	"tags": [],
	"description": "",
	"content": "The presentation\u0026hellip;\n"
},
{
	"uri": "https://covesa.github.io/vissr/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://covesa.github.io/vissr/pocs/poc1/",
	"title": "Vehicle.Speed subscription example",
	"tags": [],
	"description": "",
	"content": "Here follows a minimal example that goes through all the steps nneeded to set up a VISSv2 tech stack where a client subscribes to Vehicle.Speed, and receives simulated values in return.\nIt is assumed that the development environment has Golang installed. If not, then instruction for installing Golang is found here.\nIf this repo is not cloned to the development environment, this is done by the command:\n$ git clone https://github.com/covesa/vissr.git\nThe POC will be based on the feeder found at the feeder branch, so switching to this branch is done by the command:\n$ git checkout feeder\nAs we will use the Redis based statestorage, we will have to start the Redis daemon. A code snippet that does this is available here. If you do not already have cloned this repo, then it is done by the command:\n$ git clone https://github.com/COVESA/ccs-components\nCheck out the README here for details on how to set this up.\nNext is to build the server, which is done in a terminal window by the command (with the working directory moved to the WAII/server/vissv2server):\n$ go build\nThe server uses a binary formatted copy of the VSS tree to verify client requests, so if the signal of interest, Vehicle.Speed, is not in this tree, i is necessary to create a new binary tree containing this signal. For informtion on how to get that done, check out VSS tree configuration.\nThen start the server with the command line configuration for using Redis as statestorage:\n$ ./vissv2server -s redis\nTo build the feeder, open a new terminal and move the working directory to WAII/feeder and then apply the command:\n$ go build\nBefore strtign it, it needs to be configured for mapping of the Vehicle.Speed signal, and to generate simulated values for it. To do this the file VehicleVssMapData.json needs to be edited so that it only contains a mapping for Vehicle.Speed.\n[{\u0026ldquo;vssdata\u0026rdquo;:\u0026ldquo;Vehicle.Speed\u0026rdquo;,\u0026ldquo;vehicledata\u0026rdquo;:\u0026ldquo;CurrSpd\u0026rdquo;}]\nReplace the content of the file with the above. The name \u0026lsquo;CurrSdp\u0026rsquo; is the (imaginary) name of the speed signal used in the vehicle interface. After the feeder is configured it is started:\n$ ./feeder\nWhat is left now is to start a client and issue the subscribe request. One solution to this is to write a client, but a quicker solution is to use any of the existing clients.\nWe will here use the Javascript based client that uses the Websocket protocol.\nStart it by navigating to the directory using a file browser, then just click on it.\nAs the first field to populate is the field requesting the Ip address / URL of the server, it is necessary to find this for the computer it runs on. This can on Ubuntu be done with the command:\n$ ip addr show\nthen search for an IP address shown after the word \u0026ldquo;inet\u0026rdquo;.\nCopy the address into the field and push the Server IP button.\nThe client should then be connected to the server, which is verified b a printout in this browser tab saying \u0026ldquo;Connected\u0026rdquo;. If that is not shown, either the server is not up and running, or the IP address is not the corrt one.\nAssuming it got connected, the only thing left is to issue a subscribe request. The appclient_commands.txt contains many examples of client requests\nFrom this file, copy the request payload:\n{\u0026ldquo;action\u0026rdquo;:\u0026ldquo;subscribe\u0026rdquo;,\u0026ldquo;path\u0026rdquo;:\u0026ldquo;Vehicle/Cabin/Door/Row1/Right/IsOpen\u0026rdquo;,\u0026ldquo;filter\u0026rdquo;:{\u0026ldquo;type\u0026rdquo;:\u0026ldquo;timebased\u0026rdquo;,\u0026ldquo;parameter\u0026rdquo;:{\u0026ldquo;period\u0026rdquo;:\u0026ldquo;3000\u0026rdquo;}},\u0026ldquo;requestId\u0026rdquo;:\u0026ldquo;246\u0026rdquo;}\nAnd then edit the path to become \u0026ldquo;path\u0026rdquo;:\u0026ldquo;Vehicle.Speed\u0026rdquo;, copy this updated payload, paste it into the payload field, and push the Send button.\nAfter about three seconds an event message should be received from the server and printed into the browser tab, looking something like: { \u0026ldquo;action\u0026rdquo;: \u0026ldquo;subscription\u0026rdquo;, \u0026ldquo;subscriptionId\u0026rdquo;: \u0026ldquo;1\u0026rdquo;, “data”: {“path”: ”Vehicle.Speed”, “dp”: {“value”: ”50.0”, “ts”: ”2023-04-15T13:37:00Z”}}, \u0026ldquo;ts\u0026rdquo;: \u0026ldquo;2023-04-15T13:37:00Z\u0026rdquo; } This should every three seconds be followed by a new event message. If the feeder was configured to update this signal with simulated values, the value shown should vary accordingly, else it will be the same in every event message. If there has not been any value written into the Redis statestorage for this signal, then the value will be \u0026ldquo;Data-not-available\u0026rdquo;.\nThe server will continue to send these event messages every third second until it receives an unsubscribe request containing the subscriptionId it associated to the subscription. To send an unsubscribe request, search for it in the appclient_commands.txt file, check that the subscriptionId is correct, paste it into the payload field and push the Send button. The event message printouts should then stop, and the POC is successfully ended.\n"
},
{
	"uri": "https://covesa.github.io/vissr/server/access-control-servers/",
	"title": "VISSR Access Control Servers",
	"tags": [],
	"description": "",
	"content": "The VISSv2 access control model specifies two authorization servers:\nAccess Grant server Access Token server Access Grant server This server is in a typical scenario running in the cloud. It is built as a separate executable in the vissr/server/agt_server directory\n$ go build\nand run by\n$ ./agt_server\nIt exposes an HTTP API according to the VISSv2 specification. However it is currently not TLS protected (which is a must in non-development scenario). What is also missing in the AGS implementation is authentication of the client, which according to the specification should be an AGT task.\nAccess Token server This server runs as a thread within the vissv2 server, so it is built by the vissv2 build command. For it to be built, it is necessary to make sure that the \u0026ldquo;atServer\u0026rdquo; line in the serverComponents array in the vissv2server.go code is uncommented:\nvar serverComponents []string = []string{ \u0026#34;serviceMgr\u0026#34;, \u0026#34;httpMgr\u0026#34;, \u0026#34;wsMgr\u0026#34;, \u0026#34;mqttMgr\u0026#34;, \u0026#34;grpcMgr\u0026#34;, \u0026#34;atServer\u0026#34;, } If it is part of the vissv2server build, and if a VSS node is access control tagged, the server will then forward the access token received in the client request to the ATS for validation.\nThe ATS will as part of the validation also use the VISSv2 specified policy documents if they are found in the working directory.\nThe ATS supports caching of access tokens, and returning a token handle to the client if cached. The cache is configured to hold max 10 tokens. If the cache is full, caching of one more is rejected until a cached token becomes expired, or pre-emptied by other reasons.\nFor the AT server to verify the AGT signature it needs to have access to the AGTS public key. To facilitate that it is necessary to copy the server/agt_server/agt_public_key.rsa file to the server/vissv2server directory.\nServer configuration The configuration available for the servers is whether the protocols that they implement to expose their APIS are TLS protected or not. The same framework that is used for generating credentials for the client-server communication described here can be used in this case also. These credentials should however to follow good security practises be separate from what is used in the client-server communication. The different port number for the respective servers are shown below.\nServer Port number: No TLS Port number: TLS AGTS 7500 7443 ATS 8600 8443 VISS web client submodule This submodule implements a VISSv2 web client that exposes a UI that is considerably more sophisticated than what other clients on the VISSR repo exposes, and it is particularly helpful when it comes to the client interactions with access control involved. Check out the README on both repos for more information.\nConsent support The VISSv2 specification provides support for requesting consent from a data owner before allowing a client to access the data. The model for this is that the process for obtaining the owner consent is delegated to an External Consent framework (ECF), and the details ofthis process is out-of-scope in relation to the VISSv2 specification. What is in scope is a high-level description of the protocol between the VISSv2 server and the ECF, see the VISSv2 consent support chapter. To configure the VISSv2 server to try to connect to an ECF, it must be started with the command parameter -c\u0026quot;.\nThe figure below shows the the different steps in the dataflow that is necessary when a client wants to initiate a subscription of data that is access controlled and require consent from the data owner. The dataflow describes a scenario when the client successfully subscribes to data the require both access control and consent by the data owner. Consent can only be required in combination with requiring access control, please see the Access Control Model chapter.\nThe client issues a request to the Access Grant Token server (AGTS). 1.1 The AGTS verifies the client request and returns an Access Grant Token (AGT).\nThe client issues a request to the Access Token server (ATS). 2.1 The ATS writes the data in the client request to the Pending list, associating a reference Id to it.\n2.2 The ATS issues a request to obtain consent to the ECF, including the reference Id.\n2.3 The ATS sends a response to the client containing a reference to the entry in the Pending list.\n2.4 The ECF has obtained (a positive) consent and issues a message to the ATS containing the consent and the reference Id. The ATS updates the consent info in the Pending list (initially set to NOT_SET).\n2.5 The client issues an inquiry request to the ATS containing the reference Id.\n2.6 The entry on the Pending list is used to generate the AT, is then deleted, and a new entry containing the AT, keeping the same reference Id, is created on the Active list.\n2.7 A response containing the AT is returned to the client. If the inquiry request 2.5 happened before 2.4 then the ATS returns the same reference Id without executing 2.6, but if 2.4 happened before, so that the consent no longer has the value NOT_SET, then if the consent was set to YES, the ATS generates the Access Token (AT), and returns it to the client. If the consent was set to NO, the consent data is returned without the AT.\nThe client issues the subscribe request to the VISSv2 server containing the AT. The AT in the client request my be represented by a handle instead of the entire AT, see the Protected Resource Request chapter. 3.1 The VISSv2 server issues an AT validation request to the ATS. The ATS finds it on the Active list, and validates the AT.\n3.2 The ATS returns the validation result to the VISSv2 server, and the reference Id from the matching entry on the Active list.\n3.3 Assuming a positive AT validation, the VISSv server forwards the client subscribe request, and the reference Id, to the service manager.\n3.4 The service manager creates an entry on the subscription list containing the required data for being able to issue event messages to the client containing the requested signals. The reference Id is also saved.\n3.5 and 3.6 The service manager creates the response message associated to the request in 3.\nFrom this point on the servicemanager will when the event described in the filter data from the client request is triggered issue event messges to the client. This will continue until any of the following happens:\nA. The client issues an unsubscribe request.\nB. The ECF issues a consent cancellation request to the ATS.\nC. The AT expiry time is reached.\nAlternative A: The service manager will delete the entry on the subscription list. The corresponding entry on the Active list will remain.\nAlternative B: The ATS will delete the entry on the Active list, and issue a request to the service manager to delete the entry on the subscription list corresponding to the reference Id from its deleted entry.\nAlternative C: The ATS will delete the entry on the Active list correspnding to the reference Id received from the ECF, and issue a request to the service manager to delete the entry on the subscription list corresponding to the reference Id.\nPayload syntax for the messages in the client-to-ATGS communication: AGT request: {“action”: “agt-request”, \u0026ldquo;vin\u0026rdquo;:\u0026ldquo;pseudo-vin\u0026rdquo;, \u0026ldquo;context\u0026rdquo;:\u0026ldquo;triplet-sub-roles-see-spec\u0026rdquo;, \u0026ldquo;proof\u0026rdquo;:\u0026ldquo;ABC\u0026rdquo;, \u0026ldquo;key\u0026rdquo;:\u0026ldquo;DEF\u0026rdquo;}\nAGT response: {“action”: “agt-request”, \u0026ldquo;token\u0026rdquo;:\u0026ldquo;x.y.z\u0026rdquo;} // if successful validation\nError response: {“action”: “agt-request”, \u0026ldquo;error\u0026rdquo;:\u0026ldquo;error-reason\u0026rdquo;} // if unsuccessful validation\nPayload syntax for the messages in the client-to-ATS communication: AT request: {“action”: “at-request”, \u0026ldquo;agToken\u0026rdquo;:\u0026ldquo;x.y.z\u0026rdquo;, \u0026ldquo;purpose\u0026rdquo;:\u0026ldquo;purpose-description\u0026rdquo;, \u0026ldquo;pop\u0026rdquo;:\u0026quot;\u0026quot;} // pop shall be an empty string for access control short term flow.\nAT response 1: {“action”: “at-request”, \u0026ldquo;aToken\u0026rdquo;:\u0026ldquo;x.y.z\u0026rdquo;} ATS-\u0026gt;Client // Consent is not required.\nAT response 2: {“action”: “at-request”, \u0026ldquo;sessionId \u0026ldquo;:\u0026ldquo;reference-Id\u0026rdquo;, “consent”:”NOT_SET”} // Consent is required, and consent reply not obtained yet from ECF.\nAT inquiry request: {“action”: “at-inquiry”, \u0026ldquo;sessionId\u0026rdquo;:\u0026ldquo;reference-Id\u0026rdquo;} // may need to be issued multiple times until consent is provided by ECF.\nAT inquiry response 1: {“action”: “at-inquiry”, \u0026ldquo;aToken\u0026rdquo;:\u0026ldquo;x.y.z\u0026rdquo;, “consent”:”YES”} ATS-\u0026gt;Client // ECF has provided a positive consent.\nAT inquiry response 2: {“action”: “at-inquiry”, \u0026ldquo;sessionId \u0026ldquo;:\u0026ldquo;reference-Id\u0026rdquo;, “consent”:”NOT_SET”} // Reply is not obtained yet from ECF.\nAT inquiry response 3: {“action”: “at-inquiry”, “consent”:”NO”} // ECF has provided a negative consent.\nError response: {“action”: “same-as-in-request”, \u0026ldquo;error\u0026rdquo;:\u0026ldquo;error-reason\u0026rdquo;}\nPayload syntax for the messages in the ATS-to-ECF communication: Consent request: {“action”: “consent-ask”, “user-roles”: “triplet-sub-roles-see-spec”, “purpose”: “purpose-description”, \u0026ldquo;signal_access\u0026rdquo;: [{},..{}], “messageId”: ”reference-Id”}\nConsent reply request: {“action”: “consent-reply”, “consent”: “YES/NO”, “messageId”: ”reference-Id”}\nConsent cancellation request: {“action”: “consent-cancel”, “messageId”: ”reference-Id”}\nResponse to above requests: {“action”: “same-as-in-request”, “status”: “200-OK/404-Not found/401-Bad request”} // Status is one of the three examples shown.\nSee the specification chapterPurpose list for the definition of the signal_access object.\n"
},
{
	"uri": "https://covesa.github.io/vissr/datastore/apache-iotdb/",
	"title": "VISSR Apache IoTDB",
	"tags": [],
	"description": "",
	"content": "Introduction Description of Apache IoTDB from https://iotdb.apache.org/:\n\u0026ldquo;Apache IoTDB (Database for Internet of Things) is an IoT native database with high performance for data management and analysis, deployable on the edge and the cloud. Due to its light-weight architecture, high performance and rich feature set together with its deep integration with Apache Hadoop, Spark and Flink, Apache IoTDB can meet the requirements of massive data storage, high-speed data ingestion and complex data analysis in the IoT industrial fields.\u0026rdquo;\nScope Support for Apache IoTDB as the VISSR data store is implemented by connector code in the VISSR service manager, which connects VISSR to an external Apache IoTDB server. This code uses the IoTDB Go client to maintain a connection session to the IoTDB server, which is then used to get/set vehicle data from the database.\nAs VISSR and the IoTDB server are separate processes VISSR needs to be told where to find the IoTDB server and which storage prefix to use to access the data. The administration of the Apache IoTDB server itself, including startup and shutdown, is out of scope and is handled externally to VISSR.\nRuntime notes Assumptions Runtime assumptions:\nIoTDB server lifecycle (e.g. startup and shutdown) is handled externally to VISSR Management (e.g. creation/deletion) of the IoTDB timeseries containing VSS data is handled externally to VISSR. Configuration of the connector code is specified in the config file iotdb-config.json. If the config file is not found then build-time defaults are used. Handling of IoTDB server and timeseries management is placed outside of VISSR to allow flexible deployment through loosely coupled connections.\nDatabase schema The connector assumes a simple key/value pair schema for accessing VSS data in an IoTDB timeseries:\nVSS node names (keys) are backtick quoted when stored as measurement keys in the database e.g. `Vehicle.CurrentLocation.Longitude`. This avoids IoTDB interpreting the VSS tree path, here Vehicle.CurrentLocation., as part of its storage path which also uses a dot notation.\nVSS data is stored using native (IoTDB) data types rather than strings.\nThat the timeseries containing VSS nodes can be found using the prefix path specified in the config file.\nExample timeseries:\n+------------------------+-----------------------------------------------------+--------+--------+ | Time| Timeseries| Value|DataType| +------------------------+-----------------------------------------------------+--------+--------+ |2024-03-07T17:55:24.514Z| root.test2.dev1.`Vehicle.CurrentLocation.Longitude`|-42.4567| FLOAT| +------------------------+-----------------------------------------------------+--------+--------+ Configuration The connection code reads its runtime configuration from the JSON formatted file iotdb-config.json located in the vissv2server directory. All values should be specified.\nConfiguration file format Key name Type Description host String Hostname or IP address of the IoTDB server port String RPC port of the server. Default is 6667 username String Username to access the server. Default is root password String Password to access the server. Default is root queryPrefixPath String Timeseries prefix path of VSS data in the database queryTimeout(ms) Int Query timeout in milliseconds Example iotdb-config.json:\n{ \u0026#34;host\u0026#34;: \u0026#34;127.0.0.1\u0026#34;, \u0026#34;port\u0026#34;: \u0026#34;6667\u0026#34;, \u0026#34;username\u0026#34;: \u0026#34;root\u0026#34;, \u0026#34;password\u0026#34;: \u0026#34;root\u0026#34;, \u0026#34;queryPrefixPath\u0026#34;: \u0026#34;root.test2.dev1\u0026#34;, \u0026#34;queryTimeout(ms)\u0026#34;: 5000 } Logging The connector writes information, warning and error messages to the VISSR server log with the prefix IoTDB. Grepping in the log for that prefix string can help you quickly identify connector messages.\nQuick start notes The following notes are intended to help you quickly try out using Apache IoTDB as a data store.\nThe Apache IoTDB project website has extensive documentation on the IoTDB server.\nApache IoTDB images The Apache IoTDB community maintains pre-built server images upstream to download. Including containerised Docker images in Docker Hub. IoTDB is available in both standalone (edge) and cluster (cloud) versions. Standalone is suggested as a starting point.\nThe COVESA Central Data Service Playground provides a Docker deployment that combines an Apache IoTDB server (data store) with the VISSR VISS data server.\nSeeding the database with VSS data To seed the database with VSS data the typical steps are:\nCreate the database in the server Create a timeseries in the database populated with the VSS nodes (keys) you are interested in. Add some example data so the VISS Data Server can successfully get data. IoTDB has a very extensive collection of integrations, tools, clients and APIs that could be used to achieve this.\nExample using IoTDB CLI client The following tutorial shows an example using the IoTDB CLI client, using two methods. Firstly, in interactive mode where you type the commands and then sending the same commands in batch command mode.\nConnect to the CLI client from your host: $ bash \u0026lt;iotdb path\u0026gt;/sbin/start-cli.sh -h \u0026lt;server hostname/ip\u0026gt; Create database from CLI command line: IoTDB \u0026gt; create database root.test2.dev1 Create timeseries from CLI command line: IoTDB \u0026gt; CREATE ALIGNED TIMESERIES root.test2.dev1(`Vehicle.CurrentLocation.Longitude` FLOAT, `Vehicle.CurrentLocation.Latitude` FLOAT, `Vehicle.Cabin.Infotainment.HMI.DistanceUnit` TEXT) 4 Add some data into the timeseries:\nIoTDB\u0026gt; insert into root.test2.dev1(`Vehicle.CurrentLocation.Longitude`, `Vehicle.CurrentLocation.Latitude`, `Vehicle.Cabin.Infotainment.HMI.DistanceUnit`) values(-42.4567, 22.1234, \u0026#39;MILES\u0026#39;) Display the data just added as a sanity check: IoTDB\u0026gt; select last * from root.test2.dev1 +------------------------+-------------------------------------------------------------+--------+--------+ | Time| Timeseries| Value|DataType| +------------------------+-------------------------------------------------------------+--------+--------+ |2024-03-07T17:55:24.514Z| root.test2.dev1.`Vehicle.CurrentLocation.Longitude`|-42.4567| FLOAT| |2024-03-07T17:55:24.514Z|root.test2.dev1.`Vehicle.Cabin.Infotainment.HMI.DistanceUnit`| MILES| TEXT| |2024-03-07T17:55:24.514Z| root.test2.dev1.`Vehicle.CurrentLocation.Latitude`| 22.1234| FLOAT| +------------------------+-------------------------------------------------------------+--------+--------+ You have now seeded the database with some initial VSS data and can use VISSR to query it.\nThe CLI client startup script accepts SQL commands using the -e parameter. We can therefore use this to codify the above in a bash script. So the VSS node names (keys) are passed correctly on the command line the backticks must be escaped.\nFor example:\n# !/bin/bash host=127.0.0.1 rpcPort=6667 user=root pass=root bash ./sbin/start-cli.sh -h ${host} -p ${rpcPort} -u ${user} -pw ${pass} -e \u0026#34;create database root.test2.dev1\u0026#34; bash ./sbin/start-cli.sh -h ${host} -p ${rpcPort} -u ${user} -pw ${pass} -e \u0026#34;CREATE ALIGNED TIMESERIES root.test2.dev1(\\`Vehicle.CurrentLocation.Longitude\\` FLOAT, \\`Vehicle.CurrentLocation.Latitude\\` FLOAT, \\`Vehicle.Cabin.Infotainment.HMI.DistanceUnit\\` TEXT)\u0026#34; bash ./sbin/start-cli.sh -h ${host} -p ${rpcPort} -u ${user} -pw ${pass} -e \u0026#34;insert into root.test2.dev1(\\`Vehicle.CurrentLocation.Longitude\\`, \\`Vehicle.CurrentLocation.Latitude\\`, \\`Vehicle.Cabin.Infotainment.HMI.DistanceUnit\\`) values(-42.4567, 22.1234, \u0026#39;MILES\u0026#39;)\u0026#34; bash ./sbin/start-cli.sh -h ${host} -p ${rpcPort} -u ${user} -pw ${pass} -e \u0026#34;select last * from root.test2.dev1\u0026#34; Of course any of the programming language clients provided by IoTDB, e.g. go, python, C++, Rust, can also be used to achieve the same result.\nDevelopment notes Please see the notes in the source commit messages and related Github pull requests for the history of the development of the Apache IoTDB connection code and its integration into the VISSR Service Manager component.\nDevelopment followed the patterns set by the existing support for Redis and SQLite.\nThe connection code was first developed with Apache IoTDB v1.2.2, using the upstream standalone pre-built image and Apache IoTDB Go Client v1.1.7.\n"
},
{
	"uri": "https://covesa.github.io/vissr/server/binary-tree-config/",
	"title": "VISSR binary tree configuration",
	"tags": [],
	"description": "",
	"content": "Using the VSS project to generate the binary file This requires that the VSS repo is cloned and configured, for th latter see instructions on the repo. To generate the binary file the make file in the root directory of the repo is used, which requires that a Python virtual environment is configured before it is used for the first time. This is done by entering the VSS root directory, then issuing a command to configure the environment, and then activating it, installing the vss-tools, and deactivate it.\n$ cd vehicle_signal_specification $ python3 -m venv ~/.venv $ source ~/.venv/bin/activate (.venv)$ pip install --pre vss-tools (.venv)$ deactivate The above is only needed to be done once. It might be necessary to install both python and pip if that is not already installed on the computer, see instructions in the repo documentation. If the exporter complains when used to make the binary file also after following the instructions above, then adding the command\n(.venv)$ pip install -e . may fix it. If problems prevail it is probably necessary to create an issue at the VSS repo.\nTo then generate the VSS tree binary file the environment is activated, the make file is called to generate the binary file, and then the environment can be deactivated.\n$ source ~/.venv/bin/activate (.venv)$ make binary (.venv)$ deactivate This generates a file with a name like \u0026lsquo;vss.binary\u0026rsquo;, which then needs to be possibly renamed to a more descriptive name and then copied to the vissr/server/vissv2server/forest directory. It must also be added to the viss.him file in the same directory for the server to include it at startup.\nUsing the CVIS project to generate the binary file Another alternative for generating the binary file is to use the HIM configurator tool in the Commercial Vehicle Information Specifications repo. The CVIS project is aiming at creating signal trees tailored to the needs of other vehicle types than the passenger cars that the VSS tree is focusing on. Development is ongoing for the vehicle types Truck, Trailer, and Bus, but the project is open for development initiatives for other vehicle types. Following the patterns and rules described on the repo it is reasonably straight forward to create your own tree on your local computer.\nThe generation of a binary tree from the vspec files is here done by using the HIM configurator tool. It uses the VSS-tools exporters for the final step of generating the files, providing extended tree configuration options, see the CVIS documentation. There it is also described how the same Python virtual environment as is used in the VSS alternative is configured (if not already done so in a VSS context) and activated before using the HIM configurator. ust as in the oher alternative the binary file needs to be copied to the vissr/server/vissv2server/forest directory, and the viss.him file edited to include it.\nTagging the tree for access control and consent management If you want to configure the tree to include access control, access control tags as described in the VISSv2 - Access Control Selection chapter needs to be added to appropriate tree nodes. This can either be done by editing vspec files directly (example below), or using the VSS-Tools overlay mechanism.\nAdding read-write access control and consent to the entire VSS tree can be done by modifying the root node in the spec/VehicleSignalSpecification.vspec file as shown below. If consent should not be included then the commented line should be used instead.\nVehicle: type: branch validate: read-write+consent # validate: read-write description: High-level vehicle data. The above validate statement is inherited by all of the descendants of the node. It can be applied to any node in the tree to allow for some nodes to not be access controlled while others will be access controlled. Changing read-write to write-only leads to that the server will allow reading of the data without a token, but requiring a valid token for write requests to the data.\nIf the HIM configurator in the CVIS project is used to generate the binary tree that has been tagged as described a binary tree with the tagging data will be generated. In the case that it is the alternative using the VSS support that is used then it is necessary to also manually edit the make file to add \u0026lsquo;-e validate\u0026rsquo; in the calls to the exporters. This should be added just before the output file name in the command, c. f. how it is added in the overlay example.\nThe AT server uses the purposelist.json file to validate that a client request to access controlled data is permitted by the access token included in the request. It therefore necessary to ensure that this file contains purpose(s) that includes the data that is access controlled tagged in the tree.\nUsing a modified make file The make file in the VSS repo does not provide CLI support for inserting validate tags or using struct datatypes that refer to a separate Type definition tree, which leads to that the make file must be manually edited. To avoid having to enter into such daring endeavours a modified make file can be found in the resource directory. If this file replaces the existing VSS make file then it can be used as explained below when using the VSS as decribed above. The CVIS project is currently not updated to use this file.\nInserting \u0026lsquo;validate\u0026rsquo; tags Adding the CLI parameter NEWKEY=validate will instruct the binary exporter that it shall accept any lines with this keyword in the vspec files. Before running the command below these lines must be manually edited into the desired nodes.\n(.venv)$ make binary NEWKEY=validate Using the struct datatype The VSS rule set defines that struct datatypes shall be defined in a separate type definition tree that the \u0026lsquo;datatype\u0026rsquo; key references, see example below.\nDownloadFile: type: actuator datatype: Types.Resources.FileDescriptor # default: {\u0026#34;name\u0026#34;:\u0026#34;downloadfile.txt\u0026#34;, \u0026#34;hash\u0026#34;:\u0026#34;20e87e71b6948d6e6dd11d776e9be79c374751bb\u0026#34;, \u0026#34;uid\u0026#34;:\u0026#34;1d878212\u0026#34;) description: File to be used by the vehicle. Default contains internal filesystem path. The type tree for the example above is found in the resources directory. If the type tree is stored in the root directory of the VSS tree, then the make file can be called with the command below to generate binary representations of both trees.\n(.venv)$ make binary TYPETREE=DataTypes.vspec "
},
{
	"uri": "https://covesa.github.io/vissr/build-system/",
	"title": "VISSR Build System",
	"tags": [],
	"description": "",
	"content": "For those who prefer to directly dive into running code instead of reading a lot of documentation before geting to run it there is a Hello World example to start with.\nInstalling Golang The server and most of the other software components at this repository is written in Golang, so in order to use this repo Golang must be installed on the computer.\nSearching for \u0026ldquo;install golang\u0026rdquo; gives many hits, of which this is one:\nHow to install Go (golang) on Ubuntu Linux.\nFor other operating systems this may be helpful.\nThis project requires Go version 1.13 or above, make sure your GOROOT and GOPATH are correctly configured. Since this project uses Go modules all dependencies will automatically download when building the project the first time.\nBuilding and running As several of the Golang based Sw components on this repo can be started with command line input to configure its behavior, it is suitable to first build it (in the directory of the source code)\n$ go build\nIf the image is to be run on another platform, golang has ample cross-compilation capabilities, more can be learned here. To cross-compile, the command could look like the below.\nenv GOOS=linux GOARCH=arm64 go build -o vissv2server\nTo run it the command looks like:\n$ ./\u0026rsquo;name-of-executable\u0026rsquo; \u0026lsquo;any-command-line-config-input\u0026rsquo;\nIf the SwC supports command line configuration input it is possible to add \u0026ldquo;-h\u0026rdquo; (no quotes) on the command line, which will then show a help text. Checking the first lines of the main() function in the source code is another possibility to find out. If there is any calls to the \u0026ldquo;github.com/akamensky/argparse\u0026rdquo; lib then it is used.\nAs the configurations have a default it is always possible to run it without adding any comand line configuration input. The configuration possibilities of the different SwCs are described in the respective chapters of this tutorial.\nThe server consists of several \u0026ldquo;actors\u0026rdquo;, see the README Overview chapter. These used to be built as separate processes that communicated over the Websockets protocol. To simplify the building process of thesesoftware components the script W3CServer.sh was created. After the refactoring of these SwCs into one process with ech actor running as a separate thread, it became more convenient to build without this script, but it is still avaliable. For more details, see the \u0026ldquo;Multi-process vs single-process server implementation\u0026rdquo; chapter in the README.\nThere are multiple Software components on this repo, such as feeders, simulators, the DCT tool that are to be built as separate excutables. If it is forgotten to be mentiond in the README, one way of determining whether a separate build is needed or not is to check the package statement in the source code. If it says \u0026ldquo;package main\u0026rdquo; it is a separate executable and shall then be built and run as described above.\nLogging Logging can be command line configured at startup.\nlogging level can be set to either of [trace, debug, info, warn, error, fatal, panic]. logging output destination. It can either be written to file, or directed to standard output. The levels currently used are mainly info, warning, error. Info is appropriate during testing and debugging, while error is appropriate when performance is important.\nTesting If modifications of the server code base is done it is recommended that the following test routine is performed before pushing any commits to this repo. To test the \u0026ldquo;VISSR tech stack\u0026rdquo;, the server together with data store and feeder, the runtest.sh is available in the root directory. This bash script starts the server and the feederv3 in the background, and then the testClient is started in the terminal window. The testClient reads the testRequests.json file for the requests it will issue to the different transport protocols, and then it prints the requests and the responses in the terminal window. After each set of test requests for the same transport protocol it will wait until the keyboard return key is received, allowing the operator to gett time to inspect the request/response logs before continuing. When the MQTT protocol is run, the test.mosquitto.org broker is used which may lead to latencies between request and response. In that case the testClient prompt for reading the return key may be found mixed into the log prints, but hitting the return key will still make it continue. If some logdata looks incorrect the operator can hit ctrl-C to terminate the testClient and instead inspect the log files for the server and the feeder, found in the log directory of their respective start directories. It is up to the operator to evaluate whether the logs look correct or not, so it might be a good idea to run the script before doing any modifications lo learn how correct logs looks like. All subscribe sessions are automatically unsubscribed after 4 events have been received. This number is set in runTest.sh by the CLI parameter \u0026ldquo;-m 4\u0026rdquo;. Other numbers of event can be set by editing this number.\nIssue the following command in the root directory to run the tests:\n$ ./runtest.sh startme When the testing is completed the script should be run to terminate the server and feeder processes:\n$ ./runtest.sh stopme The file testRequests.json can be edited to add or remove test cases. It is up to the operator to ensure that subscribe trigger conditions will be met by the simulated data that the feeder injects. This data can be modified in the tripdata.json file in the feederv3 directory.\nTransport protocols The following transport protocols are supported\nHTTP Websocket MQTT gRPC They are all except MQTT enabled by the server per default.\nTo enable MQTT add the CLI command \u0026ldquo;-m\u0026rdquo; when starting the VISS server.\nTo disable any other protocol, the string array serverComponents in the vissv2server.go file contains a list of the components that are spawned on separate threads by the main server process, and these can be commented out before building the server. For the server to be operationable, the service manager, and at least one transport protocol must not be commented out.\nGo modules Go modules are used in multiple places in this project, below follows some commands that may be helpful in managing this.\n$ go mod tidy To update the dependencies to latest run\n$ go get -u ./... If working with a fix or investigating something in a dependency, you can have a local fork by adding a replace directive in the go.mod file, see below examples.\nreplace example.com/some/dependency =\u0026gt; example.com/some/dependency v1.2.3 replace example.com/original/import/path =\u0026gt; /your/forked/import/path replace example.com/project/foo =\u0026gt; ../foo For more information see https://github.com/golang/go/wiki/Modules#when-should-i-use-the-replace-directive\nDocker The server can also be built and launched using docker and docker-compose, see the Docker README. Current example builds and runs using the redis state storage together with an implementation of the feeder interfacing the remotiveLabs broker in the cloud.feeder-rl .\n"
},
{
	"uri": "https://covesa.github.io/vissr/client/",
	"title": "VISSR Clients",
	"tags": [],
	"description": "",
	"content": "Client deployment options As is shown in the figure above the VISS interface is well suited to serve clients deployed in different environments:\nCloud deployment. Typically connected via Internet connectivity. Proximity deployment. Typcially in a mobile phone connected via any short range connectivity such as Bluetooth or WiFi. In-vehicle deployment. Typically as an app in the infotainment environment. The payloads handled by the clients at any of these deployments are identical.\nThe MQTT transport protocol option, with the broker deployed in the cloud, is well suited for the client cloud deployment as the communication can traverse across subnets. The thin application layer protocol on top of MQTT that VISS defines makes it possible to keep the client-server communication, and payload compatibility.\nClient implementations There are a number of different clients avaliable on this repo, mainly in the client/client-1.0 directory.\ngRPC client The gRPC implementation uses the protobuf encoding in the VISSv2messages.proto file found here. The server currently only supports the protobuf level 1 encoding.\nMQTT client The MQTT client implements the application level protocol described in the specification.\nCSV client The CSV client is developed for testing the curve logging algorithm that Geotab has opened for public cuse. A client can equest it to be aplied to data by using a filter option.\nIt generates a comma separated (CSV) file in which it saves the curve logged data that it has reuested from the server. The CSV format makes it easy to import it into an Excel sheet and visualize it as a graph which allows it e. g. to be compared with the original, non-curved data.\nFiletransfer client This client exercises the file transfer support by the VISSR server which supports it on the Websocket protocol. The CLI command enables it to be started for either upload or download, in which case a small text file is transported(upload.txt and dlFile.txt respectively). For this to work the binary tree must contain upload and download nodes which the vss_filetransfer.binary tree has been augmented with (the rest is VSS v5.0).\nCompression client The compression client can be used for testing three payload compression variants.\nProprietary compression algorithm Protobuf encoding, level 1 Protobuf encoding, level 2 Proprietary compression algorithm This compression variant builds on a proprietary algorithm that takes advantage of knowing the VISSv2 payload format. Due to its strong dependence on the payload format it might require rewrites if/when the payload format is updated. It is not kept up to date on this and is therefore likely to crash if an unsupported payload is applied.\nProtobuf encoding The encoding uses the VISSv2messages.proto file found here. The server supports this only for the Websocket protocol, where the websocket transport manager encodes payloads before sending them, and decodes payloads directly after receiving them. The client follows the same encoding/decoding behavior, so that the use of protobuf encoding is abstracted before other layers in both the server and the client get access to the payloads. Two levels of protobuf encoding are available, level one in which paths and timestamps have the standardized text format, and level two where these fields are compressed.\nLevel 2 Level 2 compresses the VSS paths by using the VSS path list as a lookup table. Instead of using the string paths in the encoded payload the index into the array is used. Finding the index in the array for a given path is done by applying a binary search, as the array paths are sorted by the server. Going the other way, the array is simply indexed by the integer value from the protobuf encoded payload. The string based timestamps are replaced by an int32 as shown in the CompressTS() procedure found in computils.go. Level 2 achieves compression rates of around 5 or better.\nJava script clients There are a few clients that are written in Javascript, and thus when started opens in a browser. Thes clients can be quite handy for quick testing of the server functionality. Example payloads that can be used as input are found in the appclient_commands.txt file.\nHTTP client The HTTP Client requires the server IP address/URL to be written into the field for it, and the IP address button to be pushed. Thereafter paths can be written into the Get field, followed by a push of the Get button. In the case of the client writing a value to the server, the path is written into the Set field, with the value in the following field, before pushing the Post button. If the data associated with the path is access controlled, then the access token that must have been obtained via the dialogues with the two autorization servers must first be written into the field for the token. Klicking the button to the right of it preserves the token for use in multple requests.\nWebsocket client The Websocket Client requires the server IP address/URL to be written into the field for it, and the IP address button to be pushed. Thereafter JSON based payloads can be written into the Sed field, followed by a push of the Send button.\nWebsocket client (using compression) The Websocket Client requires the server IP address/URL to be written into the field for it, and the IP address button to be pushed. Thereafter JSON based payloads can be written into the Sed field, followed by a push of the Send button. The difference to the uncompressed Websocket client is that this client opens a Websocket session with the erver in which it requests a session in which proprietary compression is applied to the payloads (see chapter above).\nAccess Grant Token Server client The AGT client requests an Access Grant Token from the Access Grant Token server.\nIt requires the AGT server IP address/URL to be written into the field for it, and the Server IP button to be pushed. In the leftmost field below \u0026ldquo;agtserver\u0026rdquo; (no quotes) must be written, then in the rightmost field a request payload shall be written. A payload example can be found in the appclient_commands.txt file. The proof value must be \u0026ldquo;ABC\u0026rdquo; for a positive validation, in which case an Access Grant token is returned.\nAccess Token Server client The AT client requests an Access Token from the Access Token server.\nIt requires the AT server IP address/URL to be written into the field for it, and the Server IP button to be pushed. In the leftmost field below \u0026ldquo;atserver\u0026rdquo; (no quotes) must be written, then in the rightmost field a request payload shall be written. A payload example can be found in the appclient_commands.txt file. The token that is provided in the request must include an Access Grant token from the response of a successful reuquest to the AGT server.\nAndroid app client The client/android/covesa-vissr-app-demo directory contains an Android app that realizes a VISSv2.0 client. This was demoed at the COVESA spring 2024 AMM in Gothenburg. Presentation, Demo recording\nClients on other repos VISS Web Client The VISS web client exposes a sophisticated UI that includes support for the dialogues that a client needs to have with the authorization server in scenarios where access control is required.\nCCS client The CCS client uses either HTTP (for Get requests), or Websocket (for subscribe requests) to access data according to a list of paths in a config file, and then requesting an OVDS server to write this data into the OVDS database.\nCCS MQTT client The CCS MQTT client uses the VISSv2 MQTT based protocol to subscribe to data according to a list of paths in a config file, and then requesting an OVDS server to write this data into the OVDS database.\n"
},
{
	"uri": "https://covesa.github.io/vissr/datastore/",
	"title": "VISSR Data Storage",
	"tags": [],
	"description": "",
	"content": "The VISSR tech stack architecture contains a data storage component located between the server and the feeder(s). This data store provides a decoupling between the server data access operations and the data access operations of a feeder.\nFeeders are expected to keep the data store updated with the latest available value of the signals defined in the VSS tree, and for client read/subscribe requests the server reads from what is available in the data store. This leads to that for all client read/subscribe requests the underlying vehicle system does not get involved by instantaneously having to provide a signal value when asked for by a client.\nFor subscriptions it also enables that a more versatile menu of event trigger conditions can be available to the client than what the underlying vehicle system actually is supporting.\nClient write requests are not passed through the data store (except for the soon to be deprecated version 1 client template type), but are instead communicated over an Unix Domain Socket IPC channel directly to the feeder by the server.\nThere are currently four plugin compatible data stores available, based on the following data base solutions.\nSQLite Redis Memcached Apache IotDB The server is at startup configured via a CLI parameter which DB solution to use, default is Redis. A feeder must be configured to use the same DB, and implement the common interface for that DB. An example of this is e. g. found in the feeder/feeder-template/feederv3/feederv3.go in the method statestorageSet(path, val, ts) which implements SQLite, Redis and Memcached.\nIt may be a bit confusing that sometimes this is referred to as \u0026ldquo;data store/storage\u0026rdquo; and sometimes \u0026ldquo;state storage\u0026rdquo;. The latter name is legacy from a previous COVESA project, the Cloud \u0026amp; Connected Services project, while the former has emerged later in the COVESA architecture group work. An argument for keeping both could be to say that the state storage refers to a storage that only keeps the latest value of a signal, while the data store refers to a more general database that can also keep time series of values of a signal. There are two scenarios where the VISSv2 server operates on time series data, curve logging, and historic data, but in this server implementation these data series are temporarily stored within the server, so a \u0026ldquo;state storage\u0026rdquo; functionality is sufficient for its needs.\n"
},
{
	"uri": "https://covesa.github.io/vissr/docker-step-by-step/",
	"title": "VISSR Docker",
	"tags": [],
	"description": "",
	"content": "Intro This is a guide to setup and run the vissv2 server together with the remotiveLabs broker with recorded vehicle data. The data set is residing the remotiveLabs cloud - . There are some configuration files that needs to be set and pushed to the docker images. The docker-compose-rl.yml is depending on the Dockerfile(for building) also located in the project root. A docker directory is reserved for adding different docker setups with different data providers.\n1. feeder-rl\nThe feeder-rl has two basic commands which lets you switch dataprovider. We have \u0026ndash;dataprovider remotive or \u0026ndash;dataprovider sim. This guide will focus on using \u0026ndash;dataprovider remotive.\nVisit remotive labs cloud demo\nSelect the Turning Torso Drivecycle, and the vss configuration. Select Play, and choose select broker, choose My personal broker and then Upload. Select Go to broker In the left down corner select Broker details and copy the url and the api-key, we need them for the feeder configuration keep the page open in the browser (we will not press start yet) Edit the config.json in the feeder-rl directory, replace url and api key. { \u0026#34;tls\u0026#34;: \u0026#34;yes\u0026#34;, \u0026#34;cert_path_name\u0026#34;: \u0026#34;certificate.pem\u0026#34;, \u0026#34;name_spaces\u0026#34;: [\u0026#34;vss\u0026#34;], \u0026#34;broker_url\u0026#34;: \u0026#34;\u0026lt;broker url\u0026gt;\u0026#34;, \u0026#34;port\u0026#34;:\u0026#34;443\u0026#34;, \u0026#34;client_id\u0026#34; : \u0026#34;volvo-go-client\u0026#34;, \u0026#34;api_key\u0026#34;: \u0026#34;\u0026lt;api key\u0026gt;\u0026#34;, \u0026#34;vss_tree_path\u0026#34;: \u0026#34;../vss/vss-flat-json/normalized-json/vss_n.json\u0026#34;, \u0026#34;signalfilter\u0026#34;: [\u0026#34;Vehicle.Speed\u0026#34;,\u0026#34;Vehicle.Body.Lights.IsLeftIndicatorOn\u0026#34;,\u0026#34;Vehicle.VehicleIdentification.VIN\u0026#34;,\u0026#34;Vehicle.CurrentLocation.Latitude\u0026#34;,\u0026#34;Vehicle.CurrentLocation.Longitude\u0026#34;,\u0026#34;Vehicle.Chassis.Accelerator.PedalPosition\u0026#34;] } The signalfilter element contains the signals that we would like the broker to filter our for us. Save the file. NOTE:\nThe feeder uses the redis state storage database to handle incoming datapoints. The location of the database and its server socket communication file.\nrunning feeder-rl example:\nfeeder-rl --dataprovider remotive --rdb /tmp/docker/redisDB.sock --fch /tmp/docker/server-feeder-channel.sock For further details view the docker-compose-rl.yml located in the project root.\n2. server configuration\nThe server needs to know where it should forward its requests for writing or reading datapoints.\nEdit the file feeder-registration.json [ { \u0026#34;root\u0026#34;:\u0026#34;Vehicle\u0026#34;, \u0026#34;fname\u0026#34;:\u0026#34;/tmp/docker/server-feeder-channel.sock\u0026#34;, \u0026#34;db\u0026#34;: \u0026#34;/tmp/docker/redisDB.sock\u0026#34; } ] set the fname element to where the feeder channel socket file should reside. set the db element to where the redis database should reside. NOTE: The above file paths and file names are correct. Changing the location of these will require changes in the docker-compose yml.\n3. build and run\nlocate the docker-compose-rl.yml file in the project root build the docker containers: docker compose -f docker-compose-rl.yml build revisit the browser from step 1, press the start button, the recorded data playback starts. run the docker-compose: docker compose -f docker-compose-rl.yml up If you get the following output to the docker console you have succesfully connected and started the vissv2server:\nfeeder | {\u0026#34;file\u0026#34;:\u0026#34;feeder-rl.go:65\u0026#34;,\u0026#34;level\u0026#34;:\u0026#34;info\u0026#34;,\u0026#34;msg\u0026#34;:\u0026#34;Data written to statestorage: Name=Vehicle.Speed, Value=10.240000000000002\u0026#34;,\u0026#34;time\u0026#34;:\u0026#34;2023-11-01T11:36:13Z\u0026#34;} feeder | {\u0026#34;file\u0026#34;:\u0026#34;feeder-rl.go:65\u0026#34;,\u0026#34;level\u0026#34;:\u0026#34;info\u0026#34;,\u0026#34;msg\u0026#34;:\u0026#34;Data written to statestorage: Name=Vehicle.Speed, Value=10.32\u0026#34;,\u0026#34;time\u0026#34;:\u0026#34;2023-11-01T11:36:14Z\u0026#34;} feeder | {\u0026#34;file\u0026#34;:\u0026#34;feeder-rl.go:65\u0026#34;,\u0026#34;level\u0026#34;:\u0026#34;info\u0026#34;,\u0026#34;msg\u0026#34;:\u0026#34;Data written to statestorage: Name=Vehicle.Chassis.Accelerator.PedalPosition, Value=15.600000000000001\u0026#34;,\u0026#34;time\u0026#34;:\u0026#34;2023-11-01T11:36:14Z\u0026#34;} feeder | {\u0026#34;file\u0026#34;:\u0026#34;feeder-rl.go:65\u0026#34;,\u0026#34;level\u0026#34;:\u0026#34;info\u0026#34;,\u0026#34;msg\u0026#34;:\u0026#34;Data written to statestorage: Name=Vehicle.Speed, Value=10.399999999999999\u0026#34;,\u0026#34;time\u0026#34;:\u0026#34;2023-11-01T11:36:14Z\u0026#34;} feeder | {\u0026#34;file\u0026#34;:\u0026#34;feeder-rl.go:65\u0026#34;,\u0026#34;level\u0026#34;:\u0026#34;info\u0026#34;,\u0026#34;msg\u0026#34;:\u0026#34;Data written to statestorage: Name=Vehicle.Speed, Value=10.480000000000004\u0026#34;,\u0026#34;time\u0026#34;:\u0026#34;2023-11-01T11:36:14Z\u0026#34;} feeder | {\u0026#34;file\u0026#34;:\u0026#34;feeder-rl.go:65\u0026#34;,\u0026#34;level\u0026#34;:\u0026#34;info\u0026#34;,\u0026#34;msg\u0026#34;:\u0026#34;Data written to statestorage: Name=Vehicle.Speed, Value=10.560000000000002\u0026#34;,\u0026#34;time\u0026#34;:\u0026#34;2023-11-01T11:36:14Z\u0026#34;} feeder | {\u0026#34;file\u0026#34;:\u0026#34;feeder-rl.go:65\u0026#34;,\u0026#34;level\u0026#34;:\u0026#34;info\u0026#34;,\u0026#34;msg\u0026#34;:\u0026#34;Data written to statestorage: Name=Vehicle.Speed, Value=10.64\u0026#34;,\u0026#34;time\u0026#34;:\u0026#34;2023-11-01T11:36:14Z\u0026#34;} "
},
{
	"uri": "https://covesa.github.io/vissr/feeder/",
	"title": "VISSR Feeders",
	"tags": [],
	"description": "",
	"content": "A feeder is a Sw component that needs to implement the following tasks, depending on which template version they implement:\nThe soon to be deprecated template version 1:\nUse an interface to the data storage for writing and reading data. Use an interface to the underlying vehicle interface for reading and writing data. Translate data from the format used in the \u0026ldquo;VSS domain\u0026rdquo; to the format used in the \u0026ldquo;Vehicle domain\u0026rdquo;, and vice versa. Template version 2:\nUse an interface to the data storage for writing data. Use an interface to the underlying vehicle interface for reading and writing data. Translate data from the format used in the \u0026ldquo;VSS domain\u0026rdquo; to the format used in the \u0026ldquo;Vehicle domain\u0026rdquo;, and vice versa. Use an Unix domain socket interface for receiving \u0026ldquo;client set data\u0026rdquo; from the server. Template version 3:\nUse an interface to the data storage for writing data. Use an interface to the underlying vehicle interface for reading and writing data. Translate data from the format used in the \u0026ldquo;VSS domain\u0026rdquo; to the format used in the \u0026ldquo;Vehicle domain\u0026rdquo;, and vice versa. Use an Unix domain socket interface for receiving \u0026ldquo;client set data\u0026rdquo; from the server. Use the UDS interface to receive instructions from the server on which signals to begin/stop issuing events after writing to the data store. Use the UDS interface to issue events when instructed by he server to do so. The SW architecture shown in figure 1 shows a logical partition into the three main tasks of template version 1. The architecture shown handle all its communication with the server via the state storage. This leads to a polling paradigm and thus a potential latency and performance weakness. This architecture is therefore not found on the master branch, but available on the datastore-poll branch. There is still a feeder design for this in the feeder-template/feederv1 directory. Figure 1. Feeder software architecture unoptimized polling An improved architecture that eliminates the mentioned weaknesses for data flowing in the direction from the server to the feeder (i. e client write requests) is shown in figure 2. For write requests the server communicates directly over an IPC channel with the feeder, thus removing the need for the feeder to poll the state storage to find new write requests. Figure 2. Feeder software architecture optimized polling A feeder implementing this solution can be found in the feeder-template/feederv2 directory. This feeder can be configured to either use an SQLite, or a Redis state storage interface, please see the Datastore chapter for details.\nHowever, the solution implemented in the feederv2 template does not support that the server also can replace the polling with a more effective event based solution. For this the feeder implementation in the feeder-template/feederv3 directory needs to be used.\nThe server is able via the interface to detect whether a feeder implements version 2 or 3 of the interface. In case of version 2 it keeps poling of the data store, while for version 3 it relies on event signalling from the feeder instead. For more details of this interface, see the VISSR Server:Feeder interface chapter.\nThe feeder translation task is divided into a mapping of the signal name, and a possible scaling of the value. The instructions for how to do this is encoded into one or more configuration files that the feeder reads at startup. There are two versions of the feeder instructions, being used in template feederv1 and feederv2, respectively.\nIn version 1 this file only contains a signal name mapping, while version 2 supports also scaling instructions. For more about the telpate feeders, see the README in feeder-template directory.\nAn OEM wanting to deploy the VISSv2 tech stack needs to implement the Vehicle interface of the feeder, e. g. to implement a CAN bus interface. In the template feeders the Vehicle interface contains a minimal signal simulator that generates random values for the signals it is configured to support. All of that code should be removed and replaced by the code implementing the new interface client.\nBesides the feeder templates there is also an rl-feeder where the Vehicle interface is implemented to connect to a RemotiveLabs broker. RemotiveLabs has a public cloud version of its broker that can be used to replay trip data available in VSS format.\nThere is also an External Vehicle Interface Client EVIC feeder that enables the interface client to be implemented in a separate executable.\nData storage interface If the feeder is implemented to support multiple data base solutions, see the Data store chapter for which are currently supported, then to configure which to use could be done at startup via a CLI parameter, see e. g. how it is done in the feeder/feeder-template/feederv3/feederv3.go. There also the interface implementations to some DB solutions can be seen in the method statestorageSet(path, val, ts).\nSimulated vehicle data sources The feederv2 template contains two different simulation mechanisms that are selected via the command line configuration parameters.\nThe one configured by \u0026ldquo;internal\u0026rdquo; uses the conversion instructions data as input for which signals to simulate, which are then randomly selected and set to random values.\nThe other configured by \u0026ldquo;vssjson\u0026rdquo; tries to read the file \u0026ldquo;tripdata.json\u0026rdquo;, which must have a format as found in the example file. s seen in that file it contains an array of signal path names, and for each signal it contains an array of datapoints, i.e. timestamps and values. The data points are replayed at a constant frequency of 1 Hz. To change the frequency the time.Sleep input in the code must be changed and recompiled. This sets the rquirement on the data point arrays that their values must have been captured at this frequency, or recalculated to this frequency. Each data point array must have the same length. The simulator waps around and starts again from the beginning after reaching the end.\nThe signal names must be VSS paths as they are not processed by the conversion engine. Extending the model to instead expect \u0026ldquo;vehicle domain signals\u0026rdquo; (like CAN signal data) should be a simple coding exercise for anyone preferring that.\n"
},
{
	"uri": "https://covesa.github.io/vissr/build-system/hello-world/",
	"title": "VISSR Hello World example",
	"tags": [],
	"description": "",
	"content": "Two Hello World alternatives are available:\nNative build based example Docker based example Native build based Hello World example Building the server and many other software components require that the Golang build system is installed on the computer, please see here how to get that done. The next step is to clone the VISSR repo.\n$ git clone https://github.com/COVESA/vissr.git This is followed by going to the directory where the main server code is located, and build the server.\n$ cd vissr/server/vissv2server/ $ go build This could be followed by directly starting a client to issue requests to the server, but the server would then try to read data from an empty data store, so all responses would say \u0026lsquo;Data-not-found\u0026rsquo;. To be able to get some real data back we will therefore start a feeder that will write simulated data into the data store.\nTo do this, open a new terminal window, go to the feederv3 directory, and build the feeder.\n$ cd vissr/feeder/feeder-template/feederv3/ $ go build Now we can start the server and the feeder in respective terminal window. The server will connect to the feeder, so to avoid server logs complaining it cannot find the feeder it is preferred to start the feeder first.\n$ ./feederv3 $ ./vissv2server Both the server and the feeder will by default be configured to use Redis for the data store. This requires that Redis has been installed on the computer, how to do this can be read here. Other data stores can be configured, more info can be found here.\nNow it is time to start a client, there are many clients to be found in the client directory and subdirectories. We will here use the Javascript based client that connects via the Websocket protocol. But first we need to find out the IP address of the computer as the client connects to the server over a socket based on this address. How to do that can e. g. be found here, on Ubuntu the command\n$ ifconfig can be used. You will then have to search through a lot of information for an address that likely starts with \u0026lsquo;192.168\u0026rsquo; followed by two more segments. Please copy this and use the file browser on the computer to go to the client/client-1.0/Javascript directory. There you click on the file \u0026lsquo;wsclient_uncompressed.html\u0026rsquo;, which leads to that it starts up in the browser. You will there see a field whch says \u0026lsquo;host ip\u0026rsquo;, please paste the IP address in there and click on the button to the right that says \u0026lsquo;Server IP\u0026rsquo;. The client will then print \u0026lsquo;Status: Connected\u0026rsquo; in the area below if it succeeds to connect. Now we can start to issue client requests to the server by pasting or writing them into the field where it says \u0026lsquo;JSON payload, followed by clicking on the button \u0026lsquo;Send\u0026rsquo;. Try with the command\n{\u0026#34;action\u0026#34;:\u0026#34;get\u0026#34;,\u0026#34;path\u0026#34;:\u0026#34;Vehicle.Cabin.Door.Row1.DriverSide.IsOpen\u0026#34;,\u0026#34;requestId\u0026#34;:\u0026#34;232\u0026#34;} which should return a response like the below.\nServer: {\u0026#34;action\u0026#34;:\u0026#34;get\u0026#34;,\u0026#34;requestId\u0026#34;:\u0026#34;232\u0026#34;,\u0026#34;ts\u0026#34;:\u0026#34;2024-11-12T11:26:44.546855082Z\u0026#34;, \u0026#34;data\u0026#34;:{\u0026#34;path\u0026#34;:\u0026#34;Vehicle.Cabin.Door.Row1.DriverSide.IsOpen\u0026#34;, \u0026#34;dp\u0026#34;:{\u0026#34;value\u0026#34;:\u0026#34;Data-not-found\u0026#34;, \u0026#34;ts\u0026#34;:\u0026#34;2024-11-12T11:26:44.548180993Z\u0026#34;}}} The value is set to \u0026lsquo;Data-not-found\u0026rsquo; which is due to that the federv3 is not instructed to create simulated values for this signal. At startup the feederv3 reads the file VssVehicle.cvt which has been created by the Domain Conversion Tool. This file contains the instructions for how signals are mapped and scaled when they traverse between the \u0026lsquo;vehicle domain\u0026rsquo; and the \u0026lsquo;VSS domain\u0026rsquo;, but the feederv3 also uses this information to select which signals to create simulated values for. The cvt-file that comes with the repo only contains the five signals that can be read in the tools/DomainConversionTool/Map-VSSv0.1-CANv0.1.yaml file. So if we want to get a response with a simulated value a client request to any of these signals must be issued, e. g. like below. An alternative would be to create a new cvt-file with more signals first.\n{\u0026#34;action\u0026#34;:\u0026#34;get\u0026#34;,\u0026#34;path\u0026#34;:\u0026#34;Vehicle.Speed\u0026#34;,\u0026#34;requestId\u0026#34;:\u0026#34;232\u0026#34;} Please issue this request, se the response, wait about 30 secs and issue it again. The values returned in the two responses should differ as the feeder randomly generates new values. If not wait another 30 secs and issue it again. This could more easily be seen if a time-based subscribe request is issued:\n{\u0026#34;action\u0026#34;:\u0026#34;subscribe\u0026#34;,\u0026#34;path\u0026#34;:\u0026#34;Vehicle.Speed\u0026#34;,\u0026#34;filter\u0026#34;:{\u0026#34;variant\u0026#34;:\u0026#34;timebased\u0026#34;,\u0026#34;parameter\u0026#34;:{\u0026#34;period\u0026#34;:\u0026#34;10000\u0026#34;}},\u0026#34;requestId\u0026#34;:\u0026#34;246\u0026#34;} The server will issue event messages every ten seconds, and it can after a number of events has been received be seen that the value is randomly changed. To unsubscribe, issue the request:\n{\u0026#34;action\u0026#34;:\u0026#34;unsubscribe\u0026#34;,\u0026#34;subscriptionId\u0026#34;:\u0026#34;1\u0026#34;,\u0026#34;requestId\u0026#34;:\u0026#34;240\u0026#34;} The file client/client-1.0/Javascript/appclient_commands.txt contains examples of different requests that can be used, either as is or modified.\nThe feederv3 can at startup be configured to read simulated tripdata from files like \u0026rsquo;tripdata.json\u0026rsquo; or \u0026lsquo;speed-sawtooth.json\u0026rsquo;, the latter suitable if the curve log filter subscription is to be tested, maybe with a request like this:\n{\u0026#34;action\u0026#34;:\u0026#34;subscribe\u0026#34;,\u0026#34;path\u0026#34;:\u0026#34;Vehicle.Speed\u0026#34;,\u0026#34;filter\u0026#34;:{\u0026#34;variant\u0026#34;:\u0026#34;curvelog\u0026#34;,\u0026#34;parameter\u0026#34;:{\u0026#34;maxerr\u0026#34;:\u0026#34;2\u0026#34;,\u0026#34;bufsize\u0026#34;:\u0026#34;18\u0026#34;}},\u0026#34;requestId\u0026#34;:\u0026#34;275\u0026#34;} More simulation info can be found here. These files can easily be modified and extended with data for more signals and longer trips.\nDocker based Hello World example The COVESA Central Data Service Playground README describes a basic hello-world style sanity test for running VISSR in a Docker environment.\n"
},
{
	"uri": "https://covesa.github.io/vissr/datastore/memcached/",
	"title": "VISSR Memcached",
	"tags": [],
	"description": "",
	"content": "Memcached state storage Quoting from the Memcached site, \u0026ldquo;Memcached is an in-memory key-value store for small chunks of arbitrary data (strings, objects)\u0026rdquo;. The key is in this context the path, and the value is a JSON string containing the value and the associated time stamp.\nThe memcached store is started as a daemon, which is not automatically terminated when the server terminates. The commands below can be used to manually terminate the memcached daemon.\n$ ps -A | grep \u0026ldquo;memcached\u0026rdquo;\nthen remove it with the command\n$ kill pid\nwhere pid comes from the result of the first command.\nCommunication with the Memcached daemon is for security reasons configured to use Unix domain sockets. This requires that the socket file, and the directory it is stored in exist. If not then create it with the commands\n$ makedir path-to-socket-file-directory\n$ touch socket-file-name\n"
},
{
	"uri": "https://covesa.github.io/vissr/peripheral-components/",
	"title": "VISSR peripheral components",
	"tags": [],
	"description": "",
	"content": "A few other software components that can be useful when setting up a VISSv2 communication tech stack exists:\nAuthorization servers for access control and consent models. Open Vehicle Data Set, a relational database with a table configuration that enables it to store time series of VSS data from multiple vehicles. A \u0026ldquo;live simulator\u0026rdquo; that can read vehicle trip data stored in an OVDS database , and replay it so that it appears as live data from the recorded trip. Access control authorization servers The VISS2 specification describes an access control model involving two authorization servers:\nAccess Grant Token server Access Token server For details please read the VISSv2: Access Control, and the Consent Model chapters. To trigger the access control and consent functionality it is necessary to tag the corresponding VSS nodes as described in the spec. This can either be done by editing of the actual vspec files from the VSS/spec directory, or by creating overlay files and include them as described in VSS-tools, and then generate the VSS tree in binary format as described in VSS tree configuration.\nAccess Grant Token server (AGTS) The AGTS, which typically will be deployed off-vehicle, in the cloud, is separately built and deployed. The file agt_public_key.rsa is generated at startup, which must be copied to the AT server directory.\nAccess Token server (ATS) The ATS is deployed on a separate thread within the VISSv2 server, to include it make sure it is uncommented in the serverComponents string array in viss2server.go. The ATS uses the policy documents described in the spec when validating an access token, examples of these are available in the purposelist.json and scopelist.json files.\nOpen Vehicle Data Set (OVDS) The code to realize an OVDS database is found here. The database is realized using SQLite, so it is possible to use the SQLite API to read and write from it.\nHowever, an OVDS server is available that exposes a small set of methods for this, over HTTP. For more details, please check the README on the link.\nThere is as well an OVDS client available that connects to a VISSv2 server to fetch data that it then writes into the OVDS using the OVDS server interface.\nLive simulator The live simulator reads data from an OVDS containing recorded trip data, and then writes it into a state storage timed by the data time stamps so that it appears timing wise as when it was recorded. For more details, please check the README on the link.\nThe the test_vehicles.db file in the OVDS server directory contains trip data generously provided by Geotab Inc. It can be used as input to the live simulator, as well as the sawtooth_trip.db for simple testing.\nThe live simulator needs a copy of the list of leaf node paths (vsspathlist.json), which needs to contain at least all the paths that are to be replayed from the OVDS, and are also to be found in the VSS tree that the VISSv2 server uses.\n"
},
{
	"uri": "https://covesa.github.io/vissr/pocs/",
	"title": "VISSR POCs",
	"tags": [],
	"description": "",
	"content": "The WAII communication tech stack architecture can be realized in different \u0026ldquo;flavors\u0026rdquo;, a few different are presented here as Proof-of-Concept (POC) projects.\nPOC1: Vehicle.Speed subscription example POC2: Next POC.. "
},
{
	"uri": "https://covesa.github.io/vissr/datastore/redis/",
	"title": "VISSR Redis",
	"tags": [],
	"description": "",
	"content": "Redis state storage When a Redis database is used as the state storage then there is no explicit database file to handle as the database is managed in-memory by the Redis daemon. Instead it is necessary to configure and launch the daemon. This is already configured in the redis/redisNative.conf that is used as input in the bash command in the server/viss2server/redisNativeInit.sh file that is called at server startup.\nTo avoid multiple daemons being started, the server checks if the daemon is already running before starting an instance of it. If there is a need to terminate a running daemon, first find the daemon pid with the command\n$ ps -A | grep \u0026ldquo;redis\u0026rdquo;\nthen remove it with the command\n$ kill pid\nwhere pid comes from the result of the first command.\nCommunication with the Redis daemon is for security reasons configured to use Unix domain sockets. This requires that the socket file, and the directory it is stored in exist. If not then create it with the commands\n$ makedir path-to-socket-file-directory\n$ touch socket-file-name\nAlternative Redis server initiation If there is a need to start the Redis server a different way than what is described above then the redisInit.go file on this link will configure and launch it. The server code starting the daemon would first need to be commented out to avoid multiple instantiations.\n"
},
{
	"uri": "https://covesa.github.io/vissr/server/",
	"title": "VISSR Server",
	"tags": [],
	"description": "",
	"content": "The VISSR server is the Sw component that implements the interface that is exposed to the clients, and that must conform to the COVESA VISSv2 specification.\nBuild the server Please check the chapter VISSv2 Build System for general Golang information.\nTo build the server, open a erminal and go to the vissr/server/vissv2 directory and issue the command:\n$ go build\nConfigure the server VSS tree configuration The server has a copy of the VSS tree that it uses to verify that client requsts are valid - that there is a node in the tree that corresponds to the path in a request, if a node requires an access control token and consent permission, etc. The tree parser that is used expects the tree to have the \u0026lsquo;binary format\u0026rsquo; that the binary exporter of the VSS-Tools generates from the vspec files. More information about tree configuration here.\nCommand line configuration Starting the server with the command line option -h will show the screen below.\nusage: print [-h|--help] [--logfile] [--loglevel (trace|debug|info|warn|error|fatal|panic)] [-d|--dpop] [-p|--pathlist] [--pListPath \u0026#34;\u0026lt;value\u0026gt;\u0026#34;] [-s|--statestorage (sqlite|redis|memcache|apache-iotdb|none)] [-j|--history] [--dbfile \u0026#34;\u0026lt;value\u0026gt;\u0026#34;] [-c|--consentsupport] VISS v3.0 Server Arguments: -h --help Print help information --logfile outputs to logfile in ./logs folder --loglevel changes log output level. Default: info -d --dpop Populate tree defaults. Default: false -p --pathlist Generate pathlist file. Default: false --pListPath path to pathlist file. Default: ../ -s --statestorage Statestorage must be either sqlite, redis, memcache, apache-iotdb, or none. Default: redis -j --history Support for historic data requests. Default: false --dbfile statestorage database filename. Default: serviceMgr/statestorage.db -c --consentsupport try to connect to ECF. Default: false More information for some of the options:\n-p: Whether pathlist files should be generated or not at startup. True if is set, false if not set. \u0026ndash;pListPath \u0026lsquo;path: Path to where \u0026ldquo;pathlistX.json\u0026rdquo; file(s) are stored. X=[1..] Default is \u0026ldquo;../\u0026rdquo;. -d: Whether default values defined in the tree(s) should be copied to the data store or not at startup. True if is set, false if not set. \u0026ndash;loglevel levelx: Levelx is one of [trace, debug, info, warn, error, fatal, panic]. Default is \u0026ldquo;info\u0026rdquo;. \u0026ndash;logfile: Whether logging should end up in standard output (false) or in a log file (true). True if is set, false if not set. \u0026ndash;dbfile filepath: Only relevant if SQLite is configured via \u0026ldquo;-s sqlite\u0026rdquo;. -j: Starts up an internal server thread if true. Currently not supported even if set to true. True if is set, false if not set. -c: If set to true an ECF SwC must be available to connect to the server. True if is set, false if not set. Data storage configuration Currently the server supports two different databases, SQLite and Redis, which one to use is selected in the command line configuration. However, to get it up and running there might be other preparations also needed, please see the VISSv2 Data Storage chapter.\nProtocol support configuration The server supports the following protocols:\nHTTP Websockets MQTT (with the VISSv2 specific application protocol on top) gRPC The message payload is identical for all protocols at the client application level (after protocol specific payload modifications are restored). HTTP differs in that it does not support subscribe requests.\nThe code is structured to make it reasonably easy to remove any of the protocols if that is desired for reducing the code footprint. Similarly it should be reasonably straight forward to add new protocols, given that the payload format transformation is not too complicated.\nThe Websocket protocol manager terminates subscriptions if a client terminates the session without first terminating its ongoing subscriptions.\nEach of the transport protocol managers runs on a separate thread. If a transport protocol is of no interest to have listening for clients then it can be prevented from starting by commenting out the string element with its name in the serverComponents string array variable in the vissv2server.go file before compiling it.\nTLS configuration The server, and several of the clients, can be configured to apply TLS to the protocols (MQTT uses it integrated model for this). The first step in applying TLS is to generate the credentials needed, which is done by running the testCredGen.sh script found here.\nFor details about it, please look at the README in that directory. As described there, the generated credentials must then be copied into the appropriate directories for both the server and the client. And the key-value \u0026ldquo;transportSec\u0026rdquo; in the transportSec.json file must be set to \u0026ldquo;yes\u0026rdquo; on both sides.\nReverting to non-TLS use only requires the \u0026ldquo;yes\u0026rdquo; to be changed to \u0026ldquo;no\u0026rdquo;, on both the server and the client side. Clients must also change to the non-TLS port number according to the list below.\nProtocol Port number: No TLS Port number: TLS HTTP 8888 443 WebSocket 8080 6443 MQTT 1883 8883 gRPC 5000 5443 Pathlist file generation Some software components that are used in the overall context to setup and run a VISSv2 based communication tech stack needs a list of all the leaf node paths of the VSS tree being used y the server. The server generates such a list at startup, in the form of a sorted list in JSON format, having a default name \u0026ldquo;vsspathlist.json\u0026rdquo;. As this file may need to be copied and used in other preparations before starting the entire tech stack, it is possible to run the server to only generate this file and then terminate. SwCs that use this file:\nSQLite state storage manager. The server itself if started to apply path encoding using some of the experimental compression schemes, and the corresponding client. The protobuf encoding scheme. The live simulator. Feeder interface As described in the VISSR Feeders chapter there are two template versions of feeders. Version 2 only supports reception of Set requests from the server, while version 3 can also act on subscribe/unsubscribe requests from the server, and then issue an event to the server when it has updated a subscribed signal in the data store. The figure below shows the communication network that implements this. Figure 1. Network for feeder event communication The feeder, running in a separate process, is communicating with the server over a Unix domain socket interface. This interface is on the server side managed by the \u0026ldquo;feeder front end\u0026rdquo; thread. The \u0026ldquo;service manager\u0026rdquo; thread of the server receives set/subscribe/unsubscribe requests from clients (get requests do not affect this network) that it passes on to the feeder front end, which then analyzes the requests and decides to which other entities this should be forwarded. The subscribe request types that benefit from switching from polling to an event based paradigm are change, range, curvelog, and historic data capture. This solution supports events for the change, range, and curvelog type. The historic data capture may later also be updated to support this. The message formats for the messages passed over the UDS interface are shown below. For the message formats over the other Golang channel based interfaces, please read the code.\nFeeder front end to Feeder:\n{”action”: ”set”, \u0026ldquo;data\u0026rdquo;: {\u0026ldquo;path\u0026rdquo;:\u0026ldquo;x\u0026rdquo;, \u0026ldquo;dp\u0026rdquo;:{\u0026ldquo;value\u0026rdquo;:\u0026ldquo;y\u0026rdquo;, \u0026ldquo;ts\u0026rdquo;:\u0026ldquo;z\u0026rdquo;}}} {”action”: ”subscribe”, ”path”: [”p1”, \u0026hellip;, ”pN”]} {”action”: ”unsubscribe”, ”path”: [”p1”, \u0026hellip;, ”pN”]} Feeder to Feeder front end:\n{”action”: ”subscribe”, ”status”: “ok/nok”} {”action”: ”subscription”, ”path”: ”p”} A feeder implementing version 2 may discard messages from the Feeder front end that have the \u0026ldquo;action\u0026rdquo; set to either \u0026ldquo;subcribe\u0026rdquo; or \u0026ldquo;unsubscribe\u0026rdquo;, while a feeder implementing version 3 must respond to a subscribe request with \u0026ldquo;status\u0026rdquo; set to \u0026ldquo;ok\u0026rdquo;.\nHistory control The VISSv2 specification provides a capability for clients to issue a request for historic data. This server supports temporary recording of data that can then be requested by a client using a history filter. The model used in the implementation of this is that it is not the server that decides when to start or stop a recording, or how long to keep the recorded data, but it is controlled by some other vehicle system via a Unix domain socket based API. For more information, please see the service manager README.\nTo test this functionality there is a rudimentary history control client that can be used to instruct the server to start/stop/delete recording of signals. To reduce the amount of data that is recorded the server only saves a data value if it has changed compared to the latest captured, so to record more than a start and stop value the signals should be dynamic during a test.\nIgnition life cycle Dynamic data handled by the server, such as subscriptions, and access token caching, does not survive between ignition cycles (restart of the server).\nExperimental compression VISSv2 uses JSON as the payload format, and as JSON is a textbased format there is a potential to reduce the payload size by using compression.\nA first attempt on applying compression built on a proprietary algorithm that took advantage of knowing the VISSv2 payload format. This yielded compressions rates around 5 times (500%), but due to its strong dependence on the payload format it was hard to keep stable when the payload format evolved. The compression client can be used to test it out, but some payoads will likely crash it.\nA later compression solution was built on protobuf, using the VISSv2messages.proto file found here. For more details, see the compression client.\nThe gRPC protocol implementation, which requires that payloads are protobuf encoded, uses the VISSv2.proto file found here.\n"
},
{
	"uri": "https://covesa.github.io/vissr/datastore/sqlite/",
	"title": "VISSR SQLite",
	"tags": [],
	"description": "",
	"content": "SQLite state storage When an SQLite database is used as the state storage it is necessary to prepopulate it with one row for each VSS treeleaf node, having the path name as the key. To do this there is a statestorage_mgr that takes a file containing a list of all the pathnames, \u0026ldquo;vsspathlist.json\u0026rdquo; as input. This file is generated by the server at startup, taking the paths from the VSS tree that it has access to.\nThis SQLite DB file then needs to be moved to the vissr/server/visv2server/serviceMgr directory, where it should have the name \u0026ldquo;statestorage.db\u0026rdquo; (if server configuration is not changed to another name).\n"
},
{
	"uri": "https://covesa.github.io/vissr/tools/",
	"title": "VISSR Tools",
	"tags": [],
	"description": "",
	"content": "SwCs categorized as tools are used \u0026ldquo;off-line\u0026rdquo; to create artefacts that can then be used by the \u0026ldquo;on-line\u0026rdquo; SwCs such as the server or by feeders.\nDomain Conversion Tool The DCT creates the following:\nTwo files used by a feeder for instructions on how to convert signals between the northbound domain and a southbound domain. A file containing a YAML representation of the northbound domain, to be usd as input to the VSS-Tools binary exporter. The input to the DCT are three files: A YAML representation of signals of a northbound domain. A YAML representation of signals of a southbound domain. A YAML representation of pairs of signals from respective domain that the feeder should convert between. For more information plese see the README in the DCT directory. VSS-Tools Binary Exporter The VSS-Tools binary exporter is one of the exporters of the COVESA/VSS-Tools repo.\nHowever, running the tool is easiest done from the COVESA/VSS repo. After cloning the repo (make sure the VSS-Tools is included as a submodule) the binary exporter is run by issuing the command:\nmake binary in the root directory.\nHowever, that will create a binary format representation of the VSS standard tree. If the binary exporter is to take another data model as input the make file will need to be modified. The make file line related to the binary exporter that points to the input file (the last line below):\nbinary: gcc -shared -o ${TOOLSDIR}/binary/binarytool.so -fPIC ${TOOLSDIR}/binary/binarytool.c ${TOOLSDIR}/vspec2binary.py --uuid -u ./spec/units.yaml ./spec/VehicleSignalSpecification.vspec vss_rel_$$(cat VERSION).binary needs to be modified to point to the desired file, i.e. the part \u0026ldquo;./spec/VehicleSignalSpecification.vspec\u0026rdquo; needs to be changed.\nThe tool output, a file with the extension \u0026ldquo;.binary\u0026rdquo; will then have to be copied to the VISSR server directory, and renamed to \u0026ldquo;vss_vissv2.binary\u0026rdquo;.\n"
},
{
	"uri": "https://covesa.github.io/vissr/xtra/",
	"title": "VISSR Xtra Information",
	"tags": [],
	"description": "",
	"content": "Extra information about assorted topics.\nUsing Docker-Compose to launch a vissr instance 1. server A simple process is followed where work packages are create as issues labeled as an implementation issue. The name of the issue is also the name of the branch which is used for implementation. A pull request is created when the task is finished to push the changes to the main branch.\nCreate implementation issue Branch using the name of the issue Implement and test Merge main to local branch Create PR Gate keepers review and merge to main branch. current gate keepers: (peter winzell,Ulf Bjorkengren) Web Client Integration A Web Client written in JS developed by NICS Lab is integrated for testing purposes. It supports AGT, AT and VISS requests. It is also able to generate and store Cryptographic Keys that can be used in the Long Term flow and provides a storage and visualizer for Tokens received.\nThe WebSocket Handler serves the web client in the URL /webclient. Because of that, it can be accessed in any Web Browser supporting the used libraries in: http://viss-server-url:websocket-port/webclient.\nMore information about the Web Client can be found in https://github.com/nicslabdev/viss-web-client.\nSince the Web Client is included as a submodule, in order to use it, submodules in the project must be initialized:\n$ git submodule init $ git submodule update The version of the Web Client used is the latest tested. In order to use the latest version of the Web Client avaliable on github, the flag remote must be used to fetch and ensure that the latest commit of the Web Client repository is used.\n$ git submodule update --recursive --remote The client can also be accessed in \u0026ldquo;https://nicslabdev.github.io/viss-web-client/\u0026quot;. In order to use the web client provided in that link, CORS policies in the VISS server should be configured to allow requests from that URL.\nMulti-process vs single-process server implementation The components mentioned above that together realizes the server is available in two different implementations:\nComponents are built and deployed as separate processes/binaries, and communicate using Websocket. Components are built and deployed as threads within one common process/binary, and communicate using Go channels. These implementations are found at the branches multi-process and single-process, respectively. The master branch is a fork from the single-process branch.\nServer software architecture The server consists of the following \u0026ldquo;actors\u0026rdquo;:\nCore server HTTP manager Websocket manager MQTT manager gRPC manager Vehicle service manager Access Grant token server Access Token server The server functionality has a complexity level that warrants some thoughts on how a good software architecture could look like. Figure 1 is the current proposal on this. *Fig 1. Software architecture overview\nThe design tries to meet the following requirements:\nAbstract the details of how the service managers access the data that is represented in the tree. Support straightforward addition of further transport protocols. Support straightforward addition of further service managers. Support both the case of a singleton server through which all access goes, and the option of distributed servers that a client can access directly, after the initial service discovery. The following describes the components shown in Figure 1. Transport managers and interface. The transport manager is responsible for that the VISS v2 client-server communication is carried out according to the transport protocol the manager implements. The payload being communicated shall have the format specified in the W3C VISS v2 TRANSPORT document. A transport manager acts as a proxy between a client and the Server core, see Figure 2. The payload communicated over the Transport interface shall be identical regardless of which Transport manager the Core server communicates with. This payload shall therefore follow the format for the Websocket transport as specified in W3C VISS v2 TRANSPORT. This means that all transport managers except the Websocket transport manager must reformat the payload communicated over their respective transport protocol. The transport interface is divided into two components, a registration interface, and a data channel interface. The registration interface is used by a transport manager to register itself with the Server core. The data channel interface is used for exchanging the requests, responses, and notifications between the communication end points. The data channel must support bidirectional asynchronous communication, and should support both local and remote transport manager deployment. At the registration with the core server the transport manager receives a transport manager Id. It must then include this in all payloads forwarded to the core server, for the core server to use in its payload routing. The transport manager must also include a client Id in the payload, to enable its own routing to different app-clients. These Ids must not be part of the payload returned to the app-clients. *Fig 2. Transport SwA closeup\nTree manager and interface The tree representing the accessible data points is found on the COVESA VSS Github. There is also found a basic tree manager from which the basis of this tree manager is cloned. The tree manager abstracts the details of the tree, e. g. its format, which through the VSS tool support can be e. g. JSON, CSV, or c-native (c.f. VSS). It provides a method for searching the tree, to verify that a given path has a match in the tree, or to find all paths matching a path including wild cards. It also supports access to node internal data associated to a node reference provided by a previous search. *Fig 3. Tree SwA closeup\nService managers and interface Although the service manager internal design is anticipated to substantially differ between OEMs, the internal design in this project follows the architecture of the COVESA CCS project with a \u0026ldquo;state storage\u0026rdquo; component as the interface that the service manager interacts with. The service manager interface described here should however be common for all implementations.A service manager must first register with the Server core, in which it provides the path from tree root to the node that is the root node of the branches \u0026lsquo;owned\u0026rsquo; by this service manager. This means that the existing tree must already be populated with the branches of this service manager. A possible later extension is to allow the service manager to provide new branches to be added to the tree. Another extension could be for the service manager to also provide information whether it supports direct client access (distributed server solution), or not. But this is not supported in the current version. The service manager acts as the server in the data channel communication with the server core, so it shall provide the server core with port number and URL path at the registration. The service interface payload shall follow the same format as the transport protocol. However, client requests related to authorize and service discovery actions terminate at the Server core, and should not be issued at this interface, i. e. only requests related to get/set/subscribe/unsubscribe should be communicated here. App-client requests may lead to requests on multiple data points, which shall be resolved by the server core, and over this interface be replaced by an array of fully qualified paths. The subsequent response, or subscription notification, shall contain data from all nodes addressed in the array. The service interface is divided into two components, a registration interface, and a data channel interface. The registration interface is used by a service manager to register itself with the Server core. The data channel interface is used for exchanging the requests, responses, and notifications between the communication end points. The data channel must support bidirectional asynchronous communication, and should support both local and remote service manager deployment. In this design it is the state-storage responsibility to map the VSS path expressions to whatever vehicle internal addressing scheme that is required to execute the requested data access. It is the responsibility of the service manager to interpret the filter instructions in a subscription request, and make sure these are followed in subsequent notifications to the client. *Fig 4. Service SwA closeup\nServer core The Server core is the like the spider in the net, tying it all together. Its main tasks are:\nHandle registrations by transport managers and service managers. Payload analysis. Message routing. Access restriction management. Service discovery response. 1. Payload analysis As not all messages shall lead to a forwarded request to a related service manager, the Server core must analyze the requested action, and act according to it.\n2. Message routing The Server core must keep track of from which transport manager a request message was received, in order to return the response to the same transport manager. The core server therefore provides the transport manager with an Id at the registration, which it then will embed in all requests forwarded to the server core. As the transport manager itself needs to route payloads back to respective app-client, it also embeds a client Id in the payload. These two Ids shall follow the payload to the service manager, which then must embed it in its responses and notifications sent back to the core server. It is the responsibility of the transport manager to remove the Ids before returning payloads to an app-client.\n3. Access restriction management The Server core shall always check a tree node for which a client is requesting access to find out whether there is access restrictions tied to it. If so, it shall act as described in the VISSv2 CORE document. The authorization solution used in this project may not meet the security robustness required in a real life deployment. It shall however follow the access control model as described in the VISSvs specification.\n4. Service discovery response The response of a service discovery client request shall contain a JSON formatted tree containing all nodes under the tree node pointed to by the path. It is the responsibility of the Server core to use the tree interface to read node data for all nodes of this sub-tree, and format it into a JSON tree object to be returned to the client. *Fig 5. Server core SwA closeup\nServer configurations VSS tree The vehicle signals that the Covesa VISS v2 server manages are defined in the \u0026ldquo;vss_vissv2.binary\u0026rdquo; file in the vissv2server directory. New binary files containing the latest verision on the VSS repo can be generated by cloning the Vehicle Signal Specification repo, and then issuing a \u0026ldquo;make binary\u0026rdquo; command, see Tools usage. To use other formats. e. g. JSON, the vssparserutilities.c found in the c_native directory at the VSS Tools repo would have to implemented for that format (instead of the binary format that it currently implements). The major parts to be reimplemented are the file read/write methods, and the \u0026ldquo;atomic\u0026rdquo; data access methods. Other methods, like the search method use these atomic methods for actual data access. This file would then have to replace the current vssparserutilities.c in the server_core directory.\nVSS data sources The service manager implementation tries to open the file \u0026ldquo;statestorage.db\u0026rdquo; in the service_mgr directory. If this file exists, the service manager will then try to read the signals being addressed by the paths in client requests from this file. The file is an SQL database containing a table with a column for VSS paths, and a column for the data associated with the path. If there is no match, or if the database file was not found at server startup, then the service manager will instead generate a dummy value to be returned in the response. Dummy values are always an integer in the range from 0 to 999, from a counter that is incremented every 37 msec. New statestorage.db files can be generated by cloning the CCS-COVESA-Client repo, and then run the statestorage manager, see the statestorage directory. It is then important that the \u0026ldquo;vsspathlist.json\u0026rdquo; file being read by the statestorage manager is copied from the server directoy of this repo, where it becomes generated by the Covesa VISS v2 server at startup (from the data in the \u0026ldquo;vss_Covesa VISS v2.binary\u0026rdquo; file, and that the new statestorage database is populated with actual data, either in real time when running the W3C VISS v2 server, or preloaded with static data. The statestorage architecture allows one or more \u0026ldquo;feeders\u0026rdquo; to write data into the database, and also provides a translation table that can be preloaded for translating from a \u0026ldquo;non-VSS\u0026rdquo; address space to the VSS addres space (=VSS paths).\nPayload encoding A reference payload encoding is implemented that compresses the COVESA VISS v2 transport payloads with a ratio of around 450% to 700%. The encoding is currently only possible to activate over the WebSocket transport protocol, but it would also be possible to invoke over the HTTP protocol. To invoke it a client must set the sub-protocol to \u0026ldquo;W3C VISS v2c\u0026rdquo;, in JS something like\nsocket = new WebSocket(\u0026#34;ws://url-to-server:8080\u0026#34;, \u0026#34;W3C VISS v2c\u0026#34;); For unencoded WebSocket sessions, the sub-protocol shall be set to \u0026ldquo;W3C VISS v2\u0026rdquo;, or left out completely. The encoding uses both a lookup table to replace known data (paths, and other fixed key-values), removal of rule-based JSON reserved characters, and binary compression of actual data. The mechanism of using the sub-protocol parameter to invoke encoding scheme can easily be extended to use other compression schemes. For more information about the reference encoding, see README in the utils directory.\nAccess control The access control model in the Covesa VISS v2 specification is supported, with the exception of the authentication step. The implementation would not pass a security check, for eample the shared key for token signature verification is hardcoded with a redable text as value. The access control model architecture is shown below. More information about how the Access Control is performed can be found in the agt_server and at_server README. The WebClient README also includes information about how the Access Control is performed. The README in the client/client-1.0/Javascript directory describes the requests a client must issue first to the Access Grant Token server, and then to the Access Token server in order to obtain an Access token. HTML client implementations for respective access can also be found in the directory.\n"
}]